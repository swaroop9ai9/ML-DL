{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxFNp9-c2VbG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix,classification_report\n",
    "#set notebook display options\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns =500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kIWaR5ZpKlJ"
   },
   "source": [
    "## Dog Breed Classification\n",
    "\n",
    "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7MDmaAw2xGO"
   },
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BZWpQv1OwqYK",
    "outputId": "32c3058c-5bc7-48ba-e472-521aa2b7bf8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#mount drive to load datasets\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1q2zzIaUprk_"
   },
   "source": [
    "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp6FvAToxUFs"
   },
   "outputs": [],
   "source": [
    "#project path in google drive\n",
    "project_path = \"/content/drive/My Drive/AIML/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rydR_j8lqUei"
   },
   "source": [
    "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3350WZM4w4EL"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'train.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NHq1iBCfFjE"
   },
   "source": [
    "Repeat the same step for test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fxzynvB2YCb"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'test.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnUMhQrDfJmz"
   },
   "source": [
    "Repeat the same step for sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PyTxE8q2jLf"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G9RIxB-fOLT"
   },
   "source": [
    "Repeat the same step for labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtnEoEixbgi"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJc1lVrW_jmL"
   },
   "source": [
    "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYmJKmDqqpng"
   },
   "source": [
    "### Read labels.csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmlJ2VMY96IZ"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "1J62gPcQ_ojH",
    "outputId": "443e6aa6-927b-49c1-b729-aae0e7c52bf0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP8YAzQvqyK-"
   },
   "source": [
    "### Print the count of each category of Dogs given in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k7oyngnFCiaQ",
    "outputId": "29d66e20-71fe-4547-be72-3d71c2649dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scottish_deerhound                126\n",
      "maltese_dog                       117\n",
      "afghan_hound                      116\n",
      "entlebucher                       115\n",
      "bernese_mountain_dog              114\n",
      "shih-tzu                          112\n",
      "pomeranian                        111\n",
      "great_pyrenees                    111\n",
      "basenji                           110\n",
      "samoyed                           109\n",
      "tibetan_terrier                   107\n",
      "airedale                          107\n",
      "leonberg                          106\n",
      "cairn                             106\n",
      "japanese_spaniel                  105\n",
      "beagle                            105\n",
      "blenheim_spaniel                  102\n",
      "australian_terrier                102\n",
      "miniature_pinscher                102\n",
      "irish_wolfhound                   101\n",
      "lakeland_terrier                   99\n",
      "saluki                             99\n",
      "papillon                           96\n",
      "whippet                            95\n",
      "norwegian_elkhound                 95\n",
      "siberian_husky                     95\n",
      "pug                                94\n",
      "chow                               93\n",
      "italian_greyhound                  92\n",
      "pembroke                           92\n",
      "ibizan_hound                       91\n",
      "newfoundland                       91\n",
      "border_terrier                     91\n",
      "silky_terrier                      90\n",
      "lhasa                              90\n",
      "bedlington_terrier                 89\n",
      "dandie_dinmont                     89\n",
      "sealyham_terrier                   88\n",
      "rhodesian_ridgeback                88\n",
      "irish_setter                       88\n",
      "collie                             87\n",
      "boston_bull                        87\n",
      "old_english_sheepdog               87\n",
      "schipperke                         86\n",
      "english_foxhound                   86\n",
      "kelpie                             86\n",
      "african_hunting_dog                86\n",
      "bouvier_des_flandres               86\n",
      "weimaraner                         85\n",
      "bloodhound                         85\n",
      "bluetick                           85\n",
      "labrador_retriever                 84\n",
      "saint_bernard                      84\n",
      "english_setter                     83\n",
      "norfolk_terrier                    83\n",
      "chesapeake_bay_retriever           83\n",
      "wire-haired_fox_terrier            82\n",
      "kerry_blue_terrier                 82\n",
      "irish_terrier                      82\n",
      "yorkshire_terrier                  82\n",
      "scotch_terrier                     82\n",
      "greater_swiss_mountain_dog         82\n",
      "basset                             82\n",
      "groenendael                        82\n",
      "keeshond                           81\n",
      "malamute                           81\n",
      "gordon_setter                      81\n",
      "west_highland_white_terrier        81\n",
      "affenpinscher                      80\n",
      "toy_poodle                         80\n",
      "clumber                            80\n",
      "dingo                              80\n",
      "mexican_hairless                   80\n",
      "standard_poodle                    79\n",
      "miniature_poodle                   79\n",
      "staffordshire_bullterrier          79\n",
      "welsh_springer_spaniel             79\n",
      "toy_terrier                        79\n",
      "appenzeller                        78\n",
      "irish_water_spaniel                78\n",
      "miniature_schnauzer                78\n",
      "sussex_spaniel                     78\n",
      "norwich_terrier                    78\n",
      "black-and-tan_coonhound            77\n",
      "rottweiler                         76\n",
      "cardigan                           76\n",
      "dhole                              76\n",
      "shetland_sheepdog                  76\n",
      "german_short-haired_pointer        75\n",
      "pekinese                           75\n",
      "english_springer                   75\n",
      "great_dane                         75\n",
      "bull_mastiff                       75\n",
      "boxer                              75\n",
      "borzoi                             75\n",
      "doberman                           74\n",
      "cocker_spaniel                     74\n",
      "american_staffordshire_terrier     74\n",
      "brittany_spaniel                   73\n",
      "malinois                           73\n",
      "flat-coated_retriever              72\n",
      "curly-coated_retriever             72\n",
      "redbone                            72\n",
      "standard_schnauzer                 72\n",
      "border_collie                      72\n",
      "kuvasz                             71\n",
      "chihuahua                          71\n",
      "soft-coated_wheaten_terrier        71\n",
      "vizsla                             70\n",
      "french_bulldog                     70\n",
      "german_shepherd                    69\n",
      "walker_hound                       69\n",
      "tibetan_mastiff                    69\n",
      "giant_schnauzer                    69\n",
      "otterhound                         69\n",
      "komondor                           67\n",
      "brabancon_griffon                  67\n",
      "golden_retriever                   67\n",
      "briard                             66\n",
      "eskimo_dog                         66\n",
      "Name: breed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labels.breed.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WI94_Qcc0D4M"
   },
   "source": [
    "### Get one-hot encodings of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q48iAcY196I3"
   },
   "outputs": [],
   "source": [
    "targets = pd.Series(labels['breed'])\n",
    "one_hot_labels = pd.get_dummies(targets, sparse=True)\n",
    "one_hot_labels = np.asarray(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWaJ9naXfoiU"
   },
   "source": [
    "## Preparing training dataset\n",
    "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
    "2. Create 2 variables <br> \n",
    "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
    "     b.  y_train - Corresponding label of the dog <br>\n",
    "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
    "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ROj_b7nflYS"
   },
   "outputs": [],
   "source": [
    "img_rows = 128\n",
    "img_cols = 128\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aC2f9ecR0XGR",
    "outputId": "8e2c1f78-7a15-4529-81b1-e65b99b8f11c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:26<00:00, 387.05it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for f, img in tqdm(labels.values): # f for format ,jpg\n",
    "    train_img = cv2.imread('./train/{}.jpg'.format(f), 1,)\n",
    "    train_img_resize = cv2.resize(train_img, (img_rows, img_cols)) \n",
    "    x_train.append(train_img_resize)\n",
    "    y_train.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ioWDEgElBOs"
   },
   "source": [
    "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARn76j3U1CDa"
   },
   "outputs": [],
   "source": [
    "x_train_data = np.asarray(x_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIGuL4IItROU"
   },
   "outputs": [],
   "source": [
    "x_train_data = x_train_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diCr07cStX1f"
   },
   "outputs": [],
   "source": [
    "y_train_data = np.asarray(pd.get_dummies(y_train, sparse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdCXuAE11gZL"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpWx-pgV96Jv"
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x_train_data, y_train_data, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkL-N1jDsU8m"
   },
   "source": [
    "### Loading the test data\n",
    "Read the id column from the samples_submission.csv and store it in test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnpXdpd9b3E7"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv',encoding = \"ISO-8859-1\")\n",
    "test_img = submission['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEJqZIMbm0Jo"
   },
   "source": [
    "Run the below code to load the test image files in x_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zf7n4WG-b3Hv",
    "outputId": "f0eea718-ec41-4549-becc-06cd673fd6c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:25<00:00, 398.80it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test_feature = []\n",
    "i = 0 # initialisation\n",
    "for f in tqdm(test_img.values): # f for format ,jpg\n",
    "    img = cv2.imread('./test/{}.jpg'.format(f), 1)\n",
    "    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
    "    x_test_feature.append(img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9My6qSyDnE-_"
   },
   "source": [
    "Normalize the test data and convert it into 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93n-IntMnJGI"
   },
   "outputs": [],
   "source": [
    "x_test_data = np.asarray(x_test_feature).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_syqq_IkZ3d"
   },
   "outputs": [],
   "source": [
    "x_test_data = x_test_data/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKezNJVMsocP"
   },
   "source": [
    "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2jxTY2S96J4"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='valid', activation='relu', input_shape=(img_rows,img_cols,3,)))\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "model1.add(tf.keras.layers.Dropout(0.30))\n",
    "model1.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='valid', activation='relu'))\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(256, kernel_initializer = 'he_normal', activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7c2JrWstCFi"
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "eiINSHNLu4UU",
    "outputId": "ea9d6162-f069-4593-ba2b-a5814164d606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 64)      4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 122, 122, 64)      256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 952576)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               243859712 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 243,932,856\n",
      "Trainable params: 243,932,600\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui8EXw6_oqpR"
   },
   "source": [
    "### Use batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "IriIc37NozbK",
    "outputId": "6325e89e-8ecc-4cc9-cc20-1b3e94b7b5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 13s 210ms/step - loss: 52.9603 - accuracy: 0.0176 - val_loss: 7.1321 - val_accuracy: 0.0054\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 4.1764 - accuracy: 0.3221 - val_loss: 4.7873 - val_accuracy: 0.0108\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 2.6140 - accuracy: 0.4553 - val_loss: 4.8325 - val_accuracy: 0.0112\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 2.0249 - accuracy: 0.5541 - val_loss: 5.0967 - val_accuracy: 0.0117\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.6641 - accuracy: 0.6250 - val_loss: 5.3699 - val_accuracy: 0.0108\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.4443 - accuracy: 0.6730 - val_loss: 6.6961 - val_accuracy: 0.0117\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.2668 - accuracy: 0.7083 - val_loss: 6.1560 - val_accuracy: 0.0147\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.1931 - accuracy: 0.7279 - val_loss: 14.3876 - val_accuracy: 0.0108\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.0738 - accuracy: 0.7533 - val_loss: 9.2930 - val_accuracy: 0.0137\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 12s 194ms/step - loss: 1.0080 - accuracy: 0.7728 - val_loss: 11.8165 - val_accuracy: 0.0117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a46623390>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_x, train_y,\n",
    "          validation_data=(test_x, test_y),\n",
    "          batch_size=128, epochs=10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8hWaKmjoz69"
   },
   "source": [
    "#The model accuracy is very poor !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agJKkc6xtKiq"
   },
   "source": [
    "### Use Data Augmentation in the above model to see if the accuracy improves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Mn8qnZb3Ru"
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n",
    "                                                          featurewise_std_normalization=True,\n",
    "                                                          rotation_range=20,\n",
    "                                                          width_shift_range=0.20,\n",
    "                                                          height_shift_range=0.20,\n",
    "                                                          horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDLQVFDP96KI"
   },
   "outputs": [],
   "source": [
    "datagen.fit(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sssbaTfxlkk"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sehaRgT-96KQ"
   },
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(train_x, train_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpgM1lALM_1M"
   },
   "outputs": [],
   "source": [
    "val_generator = datagen.flow(test_x, test_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVFQJZw3x4-C"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "J1K2MqHbuPUa",
    "outputId": "5c2922db-6b35-4bfe-8c91-f6099fdedbd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-71-e0d9c5d1723f>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 31s 491ms/step - loss: 9.4648 - accuracy: 0.0123 - val_loss: 126.1069 - val_accuracy: 0.0073\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 4.8320 - accuracy: 0.0114 - val_loss: 4.8143 - val_accuracy: 0.0115\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 4.7951 - accuracy: 0.0112 - val_loss: 4.7936 - val_accuracy: 0.0115\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 4.7913 - accuracy: 0.0109 - val_loss: 4.7939 - val_accuracy: 0.0104\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 4.7873 - accuracy: 0.0124 - val_loss: 4.7865 - val_accuracy: 0.0109\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 4.7807 - accuracy: 0.0114 - val_loss: 4.7979 - val_accuracy: 0.0109\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 4.7845 - accuracy: 0.0116 - val_loss: 4.7870 - val_accuracy: 0.0109\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 4.7817 - accuracy: 0.0108 - val_loss: 4.7875 - val_accuracy: 0.0083\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 4.7780 - accuracy: 0.0102 - val_loss: 4.7873 - val_accuracy: 0.0094\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 4.7829 - accuracy: 0.0134 - val_loss: 4.7886 - val_accuracy: 0.0094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a45ef8588>"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model using fit_generator with batch_size 128 and run for 10 epochs\n",
    "model1.fit_generator(train_generator,\n",
    "                    steps_per_epoch = train_generator.n//128,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n//128,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2zmLztqo5DY"
   },
   "source": [
    "# Model accuracy is still poor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSTATrhsAo7L"
   },
   "source": [
    "### Lets use Transfer Learning\n",
    "\n",
    "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zy5JdbW6pIvD"
   },
   "source": [
    "Use the below code to load VGG16 weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrqs0zg7ApNw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# Instantiate the model with the pre-trained weights (no top)\n",
    "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
    "                 include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EItOlRBGpV_A"
   },
   "source": [
    "Print the summary of the base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "lQsEBgnlpHjH",
    "outputId": "0532f4c0-e30c-4837-92d7-b11ebcf86a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHpeOyW0qauW"
   },
   "source": [
    "### Add the following classification layers to the imported VGG Model <br>\n",
    "1. Flatten Layer\n",
    "2. Dense layer with 1024 neurons with activation as Relu\n",
    "3. Dense layer with 256 neurons with activation as Relu\n",
    "4. Dense layer with 120 neurons with activation as Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BpT4MLkqoaO"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model_vgg = tf.keras.models.Sequential()\n",
    "model_vgg.add(base_model)\n",
    "model_vgg.add(tf.keras.layers.BatchNormalization())\n",
    "model_vgg.add(tf.keras.layers.Dropout(0.30, name='dropout_1'))\n",
    "model_vgg.add(tf.keras.layers.Flatten())\n",
    "model_vgg.add(tf.keras.layers.Dense(1024, kernel_initializer = 'he_normal', activation='relu'))\n",
    "model_vgg.add(tf.keras.layers.BatchNormalization())\n",
    "model_vgg.add(tf.keras.layers.Dropout(0.30, name='dropout_2'))\n",
    "model_vgg.add(tf.keras.layers.Dense(256, kernel_initializer = 'he_normal', activation='relu'))\n",
    "model_vgg.add(tf.keras.layers.Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "DPngleyIzTaF",
    "outputId": "258543ad-3b1d-40c6-bab2-5037b3d2f596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 15,539,384\n",
      "Trainable params: 15,536,312\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeQem0pHITIj"
   },
   "source": [
    "### Make all the layers in the base_model (VGG16) to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7w9CSPvIRnX"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "39-nH1QCzwCF",
    "outputId": "e6182a9d-34da-4909-bb11-d53c02077401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 15,539,384\n",
      "Trainable params: 821,624\n",
      "Non-trainable params: 14,717,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj-BwqgfIkdv"
   },
   "source": [
    "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZk2SWvjIoRP"
   },
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model_vgg.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATTRlyzB1yIj"
   },
   "outputs": [],
   "source": [
    "model_vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='dog_breed_classification_best.h5',\n",
    "                                                          monitor='val_accuracy',\n",
    "                                                          save_best_only=True,\n",
    "                                                          mode='max',\n",
    "                                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "SJlFV3Xc0crd",
    "outputId": "86bf6d7d-8310-4388-c1a8-c03f5e5b9051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 4.2888 - accuracy: 0.1442\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.16771, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 4.2888 - accuracy: 0.1442 - val_loss: 3.6831 - val_accuracy: 0.1677\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.1153 - accuracy: 0.2569\n",
      "Epoch 00002: val_accuracy improved from 0.16771 to 0.23229, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 3.1153 - accuracy: 0.2569 - val_loss: 3.3316 - val_accuracy: 0.2323\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.7661 - accuracy: 0.3157\n",
      "Epoch 00003: val_accuracy improved from 0.23229 to 0.27187, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 2.7661 - accuracy: 0.3157 - val_loss: 2.9504 - val_accuracy: 0.2719\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.5454 - accuracy: 0.3502\n",
      "Epoch 00004: val_accuracy improved from 0.27187 to 0.29271, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 2.5454 - accuracy: 0.3502 - val_loss: 2.7898 - val_accuracy: 0.2927\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4776 - accuracy: 0.3591\n",
      "Epoch 00005: val_accuracy improved from 0.29271 to 0.31510, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 2.4776 - accuracy: 0.3591 - val_loss: 2.7692 - val_accuracy: 0.3151\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4140 - accuracy: 0.3764\n",
      "Epoch 00006: val_accuracy improved from 0.31510 to 0.32656, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 2.4140 - accuracy: 0.3764 - val_loss: 2.7340 - val_accuracy: 0.3266\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3039 - accuracy: 0.4035\n",
      "Epoch 00007: val_accuracy improved from 0.32656 to 0.32812, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 2.3039 - accuracy: 0.4035 - val_loss: 2.7585 - val_accuracy: 0.3281\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2443 - accuracy: 0.4076\n",
      "Epoch 00008: val_accuracy did not improve from 0.32812\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 2.2443 - accuracy: 0.4076 - val_loss: 2.8409 - val_accuracy: 0.3073\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1545 - accuracy: 0.4254\n",
      "Epoch 00009: val_accuracy improved from 0.32812 to 0.33906, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 2.1545 - accuracy: 0.4254 - val_loss: 2.8068 - val_accuracy: 0.3391\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1246 - accuracy: 0.4301\n",
      "Epoch 00010: val_accuracy did not improve from 0.33906\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 2.1246 - accuracy: 0.4301 - val_loss: 2.8507 - val_accuracy: 0.3271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a45d81240>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg.fit(train_generator,\n",
    "              steps_per_epoch=train_generator.n//128,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=val_generator.n//128,\n",
    "              epochs=10,\n",
    "              callbacks=[model_vgg_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqYgfpZB5jNj"
   },
   "source": [
    "# Model accuracy is VERY LOW !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YD5fAgVQIpKZ"
   },
   "source": [
    "Try to get training and validation accuracy to be more than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ukMkTge05shF",
    "outputId": "6c032504-bb75-43f5-880d-83bb4f9fb1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 is Non-Trainable\n",
      "block1_conv1 is Non-Trainable\n",
      "block1_conv2 is Non-Trainable\n",
      "block1_pool is Non-Trainable\n",
      "block2_conv1 is Non-Trainable\n",
      "block2_conv2 is Non-Trainable\n",
      "block2_pool is Non-Trainable\n",
      "block3_conv1 is Non-Trainable\n",
      "block3_conv2 is Non-Trainable\n",
      "block3_conv3 is Non-Trainable\n",
      "block3_pool is Non-Trainable\n",
      "block4_conv1 is Non-Trainable\n",
      "block4_conv2 is Non-Trainable\n",
      "block4_conv3 is Non-Trainable\n",
      "block4_pool is Non-Trainable\n",
      "block5_conv1 is Non-Trainable\n",
      "block5_conv2 is Non-Trainable\n",
      "block5_conv3 is Trainable\n",
      "block5_pool is Non-Trainable\n",
      "global_average_pooling2d is Non-Trainable\n"
     ]
    }
   ],
   "source": [
    "#Make all layers in base_model as Non-trainable\n",
    "for layer in base_model.layers:\n",
    "  if (layer.name =='block5_conv3'):\n",
    "    print(layer.name,\"is Trainable\")\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    print(layer.name,\"is Non-Trainable\")\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "aNbuTSUy_9yN",
    "outputId": "c0c60e06-a84f-4845-cba1-2da04de085a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 15,539,384\n",
      "Trainable params: 3,181,432\n",
      "Non-trainable params: 12,357,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYeexKkxAk9A"
   },
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_vgg.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tGqCvq59BP-T",
    "outputId": "c1c581b5-f0f4-445c-a91e-57f1bf6c0e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3519 - accuracy: 0.3855\n",
      "Epoch 00001: val_accuracy did not improve from 0.33906\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 2.3519 - accuracy: 0.3855 - val_loss: 3.4008 - val_accuracy: 0.2589\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9179 - accuracy: 0.4710\n",
      "Epoch 00002: val_accuracy did not improve from 0.33906\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 1.9179 - accuracy: 0.4710 - val_loss: 3.0508 - val_accuracy: 0.3161\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7082 - accuracy: 0.5223\n",
      "Epoch 00003: val_accuracy improved from 0.33906 to 0.34062, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 32s 508ms/step - loss: 1.7082 - accuracy: 0.5223 - val_loss: 2.7751 - val_accuracy: 0.3406\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5926 - accuracy: 0.5488\n",
      "Epoch 00004: val_accuracy did not improve from 0.34062\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 1.5926 - accuracy: 0.5488 - val_loss: 2.8503 - val_accuracy: 0.3292\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4715 - accuracy: 0.5814\n",
      "Epoch 00005: val_accuracy improved from 0.34062 to 0.34479, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 1.4715 - accuracy: 0.5814 - val_loss: 2.8855 - val_accuracy: 0.3448\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3809 - accuracy: 0.6042\n",
      "Epoch 00006: val_accuracy improved from 0.34479 to 0.36250, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 1.3809 - accuracy: 0.6042 - val_loss: 2.7170 - val_accuracy: 0.3625\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2996 - accuracy: 0.6182\n",
      "Epoch 00007: val_accuracy did not improve from 0.36250\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 1.2996 - accuracy: 0.6182 - val_loss: 2.9739 - val_accuracy: 0.3365\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2358 - accuracy: 0.6330\n",
      "Epoch 00008: val_accuracy did not improve from 0.36250\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 1.2358 - accuracy: 0.6330 - val_loss: 2.9031 - val_accuracy: 0.3521\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1822 - accuracy: 0.6513\n",
      "Epoch 00009: val_accuracy improved from 0.36250 to 0.38229, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 1.1822 - accuracy: 0.6513 - val_loss: 2.7796 - val_accuracy: 0.3823\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1037 - accuracy: 0.6744\n",
      "Epoch 00010: val_accuracy did not improve from 0.38229\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 1.1037 - accuracy: 0.6744 - val_loss: 2.8702 - val_accuracy: 0.3625\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0656 - accuracy: 0.6771\n",
      "Epoch 00011: val_accuracy improved from 0.38229 to 0.39115, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 1.0656 - accuracy: 0.6771 - val_loss: 2.8651 - val_accuracy: 0.3911\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9927 - accuracy: 0.7015\n",
      "Epoch 00012: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 500ms/step - loss: 0.9927 - accuracy: 0.7015 - val_loss: 3.0769 - val_accuracy: 0.3620\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9410 - accuracy: 0.7084\n",
      "Epoch 00013: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 0.9410 - accuracy: 0.7084 - val_loss: 3.0475 - val_accuracy: 0.3792\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.7162\n",
      "Epoch 00014: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 0.9270 - accuracy: 0.7162 - val_loss: 2.9975 - val_accuracy: 0.3792\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.7347\n",
      "Epoch 00015: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.8655 - accuracy: 0.7347 - val_loss: 2.9638 - val_accuracy: 0.3781\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8298 - accuracy: 0.7457\n",
      "Epoch 00016: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.8298 - accuracy: 0.7457 - val_loss: 2.9571 - val_accuracy: 0.3828\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.7565\n",
      "Epoch 00017: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 0.7947 - accuracy: 0.7565 - val_loss: 3.0389 - val_accuracy: 0.3781\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.7557\n",
      "Epoch 00018: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 489ms/step - loss: 0.7748 - accuracy: 0.7557 - val_loss: 3.0904 - val_accuracy: 0.3724\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7298 - accuracy: 0.7724\n",
      "Epoch 00019: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 489ms/step - loss: 0.7298 - accuracy: 0.7724 - val_loss: 3.1508 - val_accuracy: 0.3818\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7779\n",
      "Epoch 00020: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 489ms/step - loss: 0.7307 - accuracy: 0.7779 - val_loss: 3.2673 - val_accuracy: 0.3771\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.7767\n",
      "Epoch 00021: val_accuracy did not improve from 0.39115\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 0.7117 - accuracy: 0.7767 - val_loss: 3.2008 - val_accuracy: 0.3766\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.7962\n",
      "Epoch 00022: val_accuracy improved from 0.39115 to 0.39740, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 491ms/step - loss: 0.6570 - accuracy: 0.7962 - val_loss: 3.1761 - val_accuracy: 0.3974\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.8040\n",
      "Epoch 00023: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.6231 - accuracy: 0.8040 - val_loss: 3.2553 - val_accuracy: 0.3724\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.7953\n",
      "Epoch 00024: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 0.6507 - accuracy: 0.7953 - val_loss: 3.2098 - val_accuracy: 0.3953\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.8092\n",
      "Epoch 00025: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 0.6079 - accuracy: 0.8092 - val_loss: 3.3339 - val_accuracy: 0.3802\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.8123\n",
      "Epoch 00026: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.5999 - accuracy: 0.8123 - val_loss: 3.2759 - val_accuracy: 0.3859\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.8167\n",
      "Epoch 00027: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.5867 - accuracy: 0.8167 - val_loss: 3.3867 - val_accuracy: 0.3750\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.8189\n",
      "Epoch 00028: val_accuracy did not improve from 0.39740\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.5635 - accuracy: 0.8189 - val_loss: 3.3263 - val_accuracy: 0.3849\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8325\n",
      "Epoch 00029: val_accuracy improved from 0.39740 to 0.39792, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.5317 - accuracy: 0.8325 - val_loss: 3.3320 - val_accuracy: 0.3979\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8292\n",
      "Epoch 00030: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.5317 - accuracy: 0.8292 - val_loss: 3.4848 - val_accuracy: 0.3745\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.8384\n",
      "Epoch 00031: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.5030 - accuracy: 0.8384 - val_loss: 3.4257 - val_accuracy: 0.3901\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.8433\n",
      "Epoch 00032: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.4904 - accuracy: 0.8433 - val_loss: 3.3506 - val_accuracy: 0.3969\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.8495\n",
      "Epoch 00033: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.4701 - accuracy: 0.8495 - val_loss: 3.3829 - val_accuracy: 0.3964\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8541\n",
      "Epoch 00034: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.4650 - accuracy: 0.8541 - val_loss: 3.4309 - val_accuracy: 0.3891\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.8456\n",
      "Epoch 00035: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 0.4764 - accuracy: 0.8456 - val_loss: 3.4607 - val_accuracy: 0.3938\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8556\n",
      "Epoch 00036: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.4544 - accuracy: 0.8556 - val_loss: 3.4263 - val_accuracy: 0.3865\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8612\n",
      "Epoch 00037: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 488ms/step - loss: 0.4460 - accuracy: 0.8612 - val_loss: 3.5392 - val_accuracy: 0.3875\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8650\n",
      "Epoch 00038: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.4304 - accuracy: 0.8650 - val_loss: 3.6111 - val_accuracy: 0.3750\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8714\n",
      "Epoch 00039: val_accuracy did not improve from 0.39792\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.3982 - accuracy: 0.8714 - val_loss: 3.6500 - val_accuracy: 0.3911\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8694\n",
      "Epoch 00040: val_accuracy improved from 0.39792 to 0.40365, saving model to dog_breed_classification_best.h5\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.4156 - accuracy: 0.8694 - val_loss: 3.5466 - val_accuracy: 0.4036\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8760\n",
      "Epoch 00041: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.3963 - accuracy: 0.8760 - val_loss: 3.5226 - val_accuracy: 0.3906\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8723\n",
      "Epoch 00042: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 0.4074 - accuracy: 0.8723 - val_loss: 3.4460 - val_accuracy: 0.3984\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8724\n",
      "Epoch 00043: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 0.3981 - accuracy: 0.8724 - val_loss: 3.6715 - val_accuracy: 0.3786\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.8745\n",
      "Epoch 00044: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.3932 - accuracy: 0.8745 - val_loss: 3.6966 - val_accuracy: 0.3943\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8786\n",
      "Epoch 00045: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 0.3760 - accuracy: 0.8786 - val_loss: 3.7101 - val_accuracy: 0.3922\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8882\n",
      "Epoch 00046: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.3465 - accuracy: 0.8882 - val_loss: 3.6078 - val_accuracy: 0.3979\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8874\n",
      "Epoch 00047: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.3424 - accuracy: 0.8874 - val_loss: 3.7276 - val_accuracy: 0.3833\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8878\n",
      "Epoch 00048: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 491ms/step - loss: 0.3498 - accuracy: 0.8878 - val_loss: 3.7540 - val_accuracy: 0.3859\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8825\n",
      "Epoch 00049: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 489ms/step - loss: 0.3591 - accuracy: 0.8825 - val_loss: 4.0030 - val_accuracy: 0.3802\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8887\n",
      "Epoch 00050: val_accuracy did not improve from 0.40365\n",
      "63/63 [==============================] - 31s 489ms/step - loss: 0.3415 - accuracy: 0.8887 - val_loss: 3.6392 - val_accuracy: 0.4016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a45c484a8>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg.fit(train_generator,\n",
    "              steps_per_epoch=train_generator.n//128,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=val_generator.n//128,\n",
    "              epochs=50,\n",
    "              callbacks=[model_vgg_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msJ3okN55MES"
   },
   "source": [
    "## Summary\n",
    "### After 50 epochs the Training accuracy has improved to __91%__ and Validation accuracy has improved to __40%__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of CV_Project2_Dog_Breed_Classification_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
